# Cuda-Kernel-Optimization-Introduction-

在完成高性能计算课程proj过程中，我进行了cuda编程与优化的入门，逐渐实现对卷积算子的改进，并由此对GPU编程产生了兴趣，想要更进一步。
所以创建此项目仓库，用于保存记录cuda编程与优化的学习成果。

毕竟才刚入门，程序肯定有些的不规范的地方~

# 已有程序的简单介绍

## convolution

在 convolution.cpp 中，实现了针对可分离大卷积核的卷积算法的优化。 在main.cpp中，有调用算法的函数示例。

设计时考虑卷积核远大于BLOCK_DIM，且将线程块的线程设置为 <16, 16>。测试GPU为RTX4060 laptop>，代码运行库为HIP（在NVIDIA设备上会转换为cuda代码）

在算法本身的优化上，使用了常见的分离卷积计算。

算法流程上，使用横向卷积+转置+横向卷积+转置的方式，避免竖向卷积操作对内存的不连续访问。经过实验测试，发现两次转置+横向卷积的时间要快于一次竖向卷积。
索性将所有竖向卷积全部删除。

cuda编程的优化上，使用了共享内存并防止block conflicting，将数据导入共享内存时充分利用线程，并尽可能消去条件分支。

文件中有向量化版本的时间，但时间上甚至不如不使用共享内存的版本，后续会检查实现以及多组实验测试。

